{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSI4142 - Group 48 - Assignment 4\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "In this report, we will conduct an empirical study to evaluate a linear regression approach on a regression task. This will be conducted on the Car Details From Dekho daatset. For this study, we will follow the following steps:\n",
    "\n",
    "#### Group 48 Members\n",
    "- Ali Bhangu - 300234254\n",
    "- Justin Wang - 300234186\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Levenshtein in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.27.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from Levenshtein) (3.12.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Importing the required Python libraries\n",
    "import numpy as npy\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "import os as os\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import cityblock\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "!pip3 install Levenshtein\n",
    "import Levenshtein\n",
    "import re\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing movies_metadata.csv found. Deleting and re-extracting...\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  227M  100  227M    0     0  17.3M      0  0:00:13  0:00:13 --:--:-- 17.7M 0:00:18  0:00:01  0:00:17 16.7M 0:00:06 18.5M\n",
      "Extracting dataset...\n",
      "Archive:  the-movies-dataset.zip\n",
      "  inflating: ./credits.csv           \n",
      "  inflating: ./keywords.csv          \n",
      "  inflating: ./links.csv             \n",
      "  inflating: ./links_small.csv       \n",
      "  inflating: ./movies_metadata.csv   \n",
      "  inflating: ./ratings.csv           \n",
      "  inflating: ./ratings_small.csv     \n",
      "Deleted unwanted file: keywords.csv\n",
      "Deleted unwanted file: credits.csv\n",
      "Deleted unwanted file: links.csv\n",
      "Deleted unwanted file: links_small.csv\n",
      "Deleted unwanted file: ratings.csv\n",
      "Deleted unwanted file: ratings_small.csv\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "zip_path = \"the-movies-dataset.zip\"\n",
    "target_csv = \"movies_metadata.csv\"  # The main CSV we want to keep\n",
    "unwanted_csvs = [\"keywords.csv\", \"credits.csv\", \"links.csv\", \"links_small.csv\", \"ratings.csv\", \"ratings_small.csv\"]  # Unwanted files\n",
    "\n",
    "# Remove existing files if present\n",
    "if os.path.exists(target_csv):\n",
    "    print(f\"Existing {target_csv} found. Deleting and re-extracting...\")\n",
    "    os.remove(target_csv)\n",
    "\n",
    "# Download dataset using curl (Bash command in Jupyter Notebook)\n",
    "!curl -L -o {zip_path} https://www.kaggle.com/api/v1/datasets/download/rounakbanik/the-movies-dataset\n",
    "\n",
    "# Extract the ZIP file in the current folder\n",
    "print(\"Extracting dataset...\")\n",
    "!unzip -o {zip_path} -d .\n",
    "\n",
    "# Delete unwanted CSV files\n",
    "for file in unwanted_csvs:\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "        print(f\"Deleted unwanted file: {file}\")\n",
    "\n",
    "# Verify that the target CSV exists after extraction\n",
    "if not os.path.exists(target_csv):\n",
    "    raise FileNotFoundError(f\"Dataset not found: {target_csv}. Ensure the ZIP file was correctly extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45466 entries, 0 to 45465\n",
      "Data columns (total 24 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   adult                  45466 non-null  object \n",
      " 1   belongs_to_collection  4494 non-null   object \n",
      " 2   budget                 45466 non-null  object \n",
      " 3   genres                 45466 non-null  object \n",
      " 4   homepage               7782 non-null   object \n",
      " 5   id                     45466 non-null  object \n",
      " 6   imdb_id                45449 non-null  object \n",
      " 7   original_language      45455 non-null  object \n",
      " 8   original_title         45466 non-null  object \n",
      " 9   overview               44512 non-null  object \n",
      " 10  popularity             45461 non-null  object \n",
      " 11  poster_path            45080 non-null  object \n",
      " 12  production_companies   45463 non-null  object \n",
      " 13  production_countries   45463 non-null  object \n",
      " 14  release_date           45379 non-null  object \n",
      " 15  revenue                45460 non-null  float64\n",
      " 16  runtime                45203 non-null  float64\n",
      " 17  spoken_languages       45460 non-null  object \n",
      " 18  status                 45379 non-null  object \n",
      " 19  tagline                20412 non-null  object \n",
      " 20  title                  45460 non-null  object \n",
      " 21  video                  45460 non-null  object \n",
      " 22  vote_average           45460 non-null  float64\n",
      " 23  vote_count             45460 non-null  float64\n",
      "dtypes: float64(4), object(20)\n",
      "memory usage: 8.3+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8n/7vlzl5wn25x2wt_mzqszvnbm0000gn/T/ipykernel_52827/621069896.py:1: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  movieSet = pd.read_csv(target_csv)\n"
     ]
    }
   ],
   "source": [
    "movieSet = pd.read_csv(target_csv)\n",
    "print(\"Dataset loaded successfully.\")\n",
    "\n",
    "movieSet.head()\n",
    "movieSet.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing The Dataset: Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Cleaning: \n",
    "\n",
    "Within this section, we will be running 3 tests to analyze and assess our data. We have chosen to run a presence check, an exact-duplicate check, and a format check. Followed by outlier detection, with a function to replace the outliers with their mean imputated values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exact Duplcate Check:\n",
    "\n",
    "After validating the presence check for the attributes we deemed critical, we replaced the missing values in revenue and runtime with their respective mean values via mean imputation and utilized an Abritrary Value of 2000-01-01 (Janaury 1st, 2000) for the missing release dates. \n",
    "\n",
    "\n",
    "\n",
    "Now, we are opting to run an exact duplicate check on our dataset, to remove any discrepancies and accidentally duplicated data within the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exact Duplicate Checker: \n",
    "movieSet.info()\n",
    "\n",
    "# Function to check for exact duplicates, dropping the duplicates and keeping the first instance and ensuring the index is reset.\n",
    "movieSetNew = movieSet.drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "print(\"Duplicates removed successfully.\")\n",
    "\n",
    "# Checking the new dataset\n",
    "movieSetNew.head() \n",
    "movieSetNew.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Presence Checker:\n",
    "\n",
    "After running the Exact Duplicate Check, we have opted to run a Presence Check via a modified and enhanced version of our presence checker from Assignment 2 & Assignment 3. We plan to replace missing values in the key attributes with either their mean value, via mean imputation, or via arbitrary values, such as for release date, we will utilize a value of 2000-01-01 (January 1st, 2000) for the missing release dates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values detected in the following columns:\n",
      "\n",
      "Column 'release_date': 87 missing values\n",
      "     release_date\n",
      "711           NaN\n",
      "734           NaN\n",
      "3460          NaN\n",
      "3628          NaN\n",
      "5879          NaN\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Column 'revenue': 6 missing values\n",
      "       revenue\n",
      "19729      NaN\n",
      "19730      NaN\n",
      "29502      NaN\n",
      "29503      NaN\n",
      "35586      NaN\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "release_date    87\n",
       "revenue          6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def presence_checker(df, columns=[\"genres\", \"budget\", \"original_title\", \"release_date\", \"revenue\", \"runtime\"]):\n",
    "    # Filter DataFrame to only check the specified columns\n",
    "    selected_df = df[columns]\n",
    "    \n",
    "    # Count missing values in selected columns\n",
    "    missing_counts = selected_df.isna().sum()\n",
    "    \n",
    "    # Filter to only columns that have missing values\n",
    "    missing_summary = missing_counts[missing_counts > 0]\n",
    "    \n",
    "    if missing_summary.empty:\n",
    "        print(\"No missing values found in the specified columns.\")\n",
    "    else:\n",
    "        print(\"Missing values detected in the following columns:\\n\")\n",
    "        for column, count in missing_summary.items():\n",
    "            print(f\"Column '{column}': {count} missing values\")\n",
    "            print(df[df[column].isna()][[column]].head(min(5, count)))  # Show up to 5 examples\n",
    "            print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "    \n",
    "    return missing_summary\n",
    "\n",
    "presence_checker(movieSet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the missing values we have found after our check, we decided to replace the numerical categories missing values with their mean and for the release-date attribute, we have opted on using Arbitrary Values to input 2000-01-01 for the missing release dates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values found in the specified columns.\n",
      "No missing values found in the specified columns.\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Mean Imputation \n",
    "def fill_na_with_mean(df, target_column):\n",
    "    mean_value = df[target_column].mean()  # Calculate mean of the column\n",
    "    df[target_column] = df[target_column].fillna(mean_value)  # Replace NaNs with mean\n",
    "    return df\n",
    "\n",
    "fill_na_with_mean(movieSet, \"runtime\")\n",
    "presence_checker(movieSet, [\"runtime\"])\n",
    "\n",
    "fill_na_with_mean(movieSet, \"revenue\")\n",
    "presence_checker(movieSet, [\"revenue\"])\n",
    "\n",
    "# Replace NaN values in 'release_date' with \"2000-01-01\"\n",
    "movieSet['release_date'] = movieSet['release_date'].fillna(\"2000-01-01\")\n",
    "\n",
    "# Arbitrary Value Filled: \n",
    "missing_release_date = movieSet['release_date'].isna().sum()\n",
    "print(missing_release_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format Checker\n",
    "For our last portion of the data cleaning, we have opted to utilize our Format Checker from Assignment 2, we have decided to run it on the release_date column as the format is in the regex pattern of `pattern = r'^\\d{4}-\\d{2}-\\d{2}$'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 data points in release_date that do not match the format ^\\d{4}-\\d{2}-\\d{2}$. \n",
      "See below for examples if there are mismatched rows:\n",
      "\n",
      "Here are some of the rows of mismatched format:\n",
      "                                                   adult  \\\n",
      "19730                                 - Written by Ørnås   \n",
      "29503   Rune Balot goes to a casino connected to the ...   \n",
      "35587   Avalanche Sharks tells the story of a bikini ...   \n",
      "\n",
      "      belongs_to_collection                            budget  \\\n",
      "19730              0.065736  /ff9qCepilowshEtG2GYWwzt2bs4.jpg   \n",
      "29503              1.931659  /zV8bHuSL6WXoD6FWogP9j4x80bL.jpg   \n",
      "35587              2.185485  /zaSf5OG7V8X8gqFvly88zDdRm46.jpg   \n",
      "\n",
      "                                                  genres  \\\n",
      "19730  [{'name': 'Carousel Productions', 'id': 11176}...   \n",
      "29503  [{'name': 'Aniplex', 'id': 2883}, {'name': 'Go...   \n",
      "35587  [{'name': 'Odyssey Media', 'id': 17161}, {'nam...   \n",
      "\n",
      "                                                homepage          id imdb_id  \\\n",
      "19730  [{'iso_3166_1': 'CA', 'name': 'Canada'}, {'iso...  1997-08-20       0   \n",
      "29503  [{'iso_3166_1': 'US', 'name': 'United States o...  2012-09-29       0   \n",
      "35587           [{'iso_3166_1': 'CA', 'name': 'Canada'}]  2014-01-01       0   \n",
      "\n",
      "      original_language                            original_title  overview  \\\n",
      "19730             104.0  [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
      "29503              68.0      [{'iso_639_1': 'ja', 'name': '日本語'}]  Released   \n",
      "35587              82.0  [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
      "\n",
      "       ... release_date       revenue    runtime spoken_languages status  \\\n",
      "19730  ...            1  1.120935e+07  94.128199              NaN    NaN   \n",
      "29503  ...           12  1.120935e+07  94.128199              NaN    NaN   \n",
      "35587  ...           22  1.120935e+07  94.128199              NaN    NaN   \n",
      "\n",
      "       tagline  title video vote_average vote_count  \n",
      "19730      NaN    NaN   NaN          NaN        NaN  \n",
      "29503      NaN    NaN   NaN          NaN        NaN  \n",
      "35587      NaN    NaN   NaN          NaN        NaN  \n",
      "\n",
      "[3 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Column we are checking: \n",
    "column = 'release_date'\n",
    "# Please enter the regex pattern you would like to check for\n",
    "pattern = r'^\\d{4}-\\d{2}-\\d{2}$'\n",
    "\n",
    "# Format Check Test: \n",
    "def format_checker(df, column, pattern):\n",
    "    # creating the regex pattern\n",
    "    regex = re.compile(pattern)\n",
    "    \n",
    "    # Applying the regex pattern to the column and filters the rows that don't match\n",
    "    mismatched_rows = df[~df[column].astype(str).apply(lambda x: bool(regex.match(x)))]\n",
    "    total_mismatched = mismatched_rows.shape[0]\n",
    "    \n",
    "    # Printing the results of the format check. \n",
    "    print(f\"There are {total_mismatched} data points in {column} that do not match the format {pattern}. \\nSee below for examples if there are mismatched rows:\")\n",
    "    \n",
    "    # Outputting the mismatched rows for the user to see\n",
    "    if total_mismatched > 0:\n",
    "        print(\"\\nHere are some of the rows of mismatched format:\")\n",
    "        print(mismatched_rows.head(3))  \n",
    "\n",
    "# Running the function with parameters defined above:\n",
    "format_checker(movieSet, column, pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formatting Genres\n",
    "\n",
    "We have opted to format genres in an acceptable way instead of as they are currently outputted. We are using Python's built-in Abstract Syntax Tree list into our program to utilize. This way we have our genres formatted in a manner that we can utilize in our studies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>30000000</td>\n",
       "      <td>[Animation, Comedy, Family]</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000000</td>\n",
       "      <td>[Adventure, Fantasy, Family]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>262797249.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Roll the dice and unleash the excitement!</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 119050, 'name': 'Grumpy Old Men Collect...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Romance, Comedy]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15602</td>\n",
       "      <td>tt0113228</td>\n",
       "      <td>en</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Still Yelling. Still Fighting. Still Ready for...</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>False</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16000000</td>\n",
       "      <td>[Comedy, Drama, Romance]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31357</td>\n",
       "      <td>tt0114885</td>\n",
       "      <td>en</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>81452156.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Friends are the people who let you be yourself...</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>False</td>\n",
       "      <td>6.1</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 96871, 'name': 'Father of the Bride Col...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Comedy]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11862</td>\n",
       "      <td>tt0113041</td>\n",
       "      <td>en</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-02-10</td>\n",
       "      <td>76578911.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Just When His World Is Back To Normal... He's ...</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>False</td>\n",
       "      <td>5.7</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult                              belongs_to_collection    budget  \\\n",
       "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
       "1  False                                                NaN  65000000   \n",
       "2  False  {'id': 119050, 'name': 'Grumpy Old Men Collect...         0   \n",
       "3  False                                                NaN  16000000   \n",
       "4  False  {'id': 96871, 'name': 'Father of the Bride Col...         0   \n",
       "\n",
       "                         genres                              homepage     id  \\\n",
       "0   [Animation, Comedy, Family]  http://toystory.disney.com/toy-story    862   \n",
       "1  [Adventure, Fantasy, Family]                                   NaN   8844   \n",
       "2             [Romance, Comedy]                                   NaN  15602   \n",
       "3      [Comedy, Drama, Romance]                                   NaN  31357   \n",
       "4                      [Comedy]                                   NaN  11862   \n",
       "\n",
       "     imdb_id original_language               original_title  \\\n",
       "0  tt0114709                en                    Toy Story   \n",
       "1  tt0113497                en                      Jumanji   \n",
       "2  tt0113228                en             Grumpier Old Men   \n",
       "3  tt0114885                en            Waiting to Exhale   \n",
       "4  tt0113041                en  Father of the Bride Part II   \n",
       "\n",
       "                                            overview  ... release_date  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...  ...   1995-10-30   \n",
       "1  When siblings Judy and Peter discover an encha...  ...   1995-12-15   \n",
       "2  A family wedding reignites the ancient feud be...  ...   1995-12-22   \n",
       "3  Cheated on, mistreated and stepped on, the wom...  ...   1995-12-22   \n",
       "4  Just when George Banks has recovered from his ...  ...   1995-02-10   \n",
       "\n",
       "       revenue runtime                                   spoken_languages  \\\n",
       "0  373554033.0    81.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "1  262797249.0   104.0  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...   \n",
       "2          0.0   101.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "3   81452156.0   127.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "4   76578911.0   106.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "\n",
       "     status                                            tagline  \\\n",
       "0  Released                                                NaN   \n",
       "1  Released          Roll the dice and unleash the excitement!   \n",
       "2  Released  Still Yelling. Still Fighting. Still Ready for...   \n",
       "3  Released  Friends are the people who let you be yourself...   \n",
       "4  Released  Just When His World Is Back To Normal... He's ...   \n",
       "\n",
       "                         title  video vote_average vote_count  \n",
       "0                    Toy Story  False          7.7     5415.0  \n",
       "1                      Jumanji  False          6.9     2413.0  \n",
       "2             Grumpier Old Men  False          6.5       92.0  \n",
       "3            Waiting to Exhale  False          6.1       34.0  \n",
       "4  Father of the Bride Part II  False          5.7      173.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_genres(df, column):\n",
    "    df[column] = df[column].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else [])\n",
    "    df[column] = df[column].apply(lambda x: [genre['name'] for genre in x] if isinstance(x, list) else [])\n",
    "    return df\n",
    "\n",
    "clean_genres(movieSet, \"genres\")\n",
    "movieSet.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Study 1 - Similarity Measures \n",
    "\n",
    "Within this section, we are conducting the following: \n",
    "\n",
    "1. Picking a subset of 5 attributes (e.g. Genre, Revenue, Runtime, Title, Budget) in your dataset. \n",
    "- The subset of attributes should allow you to explore at least 3 different similarity measures (e.g. Jaccard, Hamming, Cosine, Euclidian, Manhattan). You should also explore an additional similarity measure on textual data (which we have not talked about in class). \n",
    "\n",
    "2. Simulate 5 requests to show the results of your 5 similarity measures. \n",
    "\n",
    "3. For each request, show the Top 10 results (ranked on the criteria that you choose). \n",
    "- For example, for the movies, I could decide to rank on popularity.\n",
    "\n",
    "\n",
    "We have opted to utilize the following 5 attributes:\n",
    "1. Budget\n",
    "2. Genre\n",
    "3. Runtime\n",
    "4. Title \n",
    "5. Revenue\n",
    "\n",
    "And the following Similarity Measures:\n",
    "1. Jaccard\n",
    "2. Euclidean \n",
    "3. Cosine \n",
    "4. For Textual Data : Levenshtein Distance Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jaccard Distance Function: \n",
    "def jaccard_similarity(set1, set2):\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union != 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean Distance Function: \n",
    "\n",
    "# Using the Scipy Library to calculate the distance between two points\n",
    "def euclidean_distance(val1, val2):\n",
    "    return euclidean([val1], [val2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine Similarity Function:\n",
    "\n",
    "# Using the SKLearn Library to calculate the cosine similarity between two points\n",
    "def cosine_sim(val1, val2):\n",
    "    return cosine_similarity([[val1]], [[val2]])[0][0] if val1 and val2 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levenshtein Distance Function:\n",
    "\n",
    "# Using the Levenshtein Library to calculate the distance between two strings\n",
    "def edit_distance(title1, title2):\n",
    "    return Levenshtein.distance(title1.lower(), title2.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manhattan Distance Function: \n",
    "# Using the Scipy Library and the City Block function to calculate the distance between two points\n",
    "def manhattan_distance(val1, val2):\n",
    "    return cityblock([val1], [val2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function For Testing:\n",
    "\n",
    "If higher_is_better = True:\n",
    "\n",
    "The function sorts the results in descending order (from highest to lowest similarity score).\n",
    "This is useful when using Jaccard Similarity or Cosine Similarity, where higher scores indicate greater similarity.\n",
    "Example: Genre Similarity (Jaccard Score: 0.9 is better than 0.5).\n",
    "If higher_is_better = False:\n",
    "\n",
    "The function sorts the results in ascending order (from lowest to highest distance).\n",
    "This is useful for distance-based measures like Euclidean or Manhattan Distance, where lower values indicate closer matches.\n",
    "Example: Revenue Similarity (a difference of $10M is better than $500M)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_similar_movies(target_movie, column, similarity_func, higher_is_better=True):\n",
    "    if target_movie not in movieSet['original_title'].values:\n",
    "        return f\"Movie '{target_movie}' not found in dataset.\"\n",
    "\n",
    "    target_value = movieSet[movieSet['original_title'] == target_movie][column].values[0]\n",
    "\n",
    "    similarities = []\n",
    "    for _, row in movieSet.iterrows():\n",
    "        if row['original_title'] != target_movie:\n",
    "            # Ensure genres are converted to sets for Jaccard Similarity\n",
    "            if column == \"genres\":\n",
    "                similarity = similarity_func(set(target_value), set(row[column]))\n",
    "            else:\n",
    "                similarity = similarity_func(target_value, row[column])\n",
    "            similarities.append((row['original_title'], similarity))\n",
    "\n",
    "    # Sort results\n",
    "    sorted_results = sorted(similarities, key=lambda x: x[1], reverse=higher_is_better)\n",
    "\n",
    "    # Return top 10 similar movies\n",
    "    return sorted_results[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_similar_movies(target_movie, column, similarity_func, higher_is_better=True):\n",
    "    \"\"\"\n",
    "    Finds the top 10 most similar movies based on a given similarity function.\n",
    "\n",
    "    Parameters:\n",
    "    target_movie (str): The name of the reference movie.\n",
    "    column (str): The column to compare (e.g., 'genres', 'budget', 'revenue').\n",
    "    similarity_func (function): The similarity function to use.\n",
    "    higher_is_better (bool): Whether a higher similarity score is better (default: True).\n",
    "\n",
    "    Returns:\n",
    "    List of tuples with movie title and similarity score.\n",
    "    \"\"\"\n",
    "    if target_movie not in movieSet['original_title'].values:\n",
    "        return f\"Movie '{target_movie}' not found in dataset.\"\n",
    "\n",
    "    # Get the target movie's value for comparison\n",
    "    target_value = movieSet.loc[movieSet['original_title'] == target_movie, column].values[0]\n",
    "\n",
    "    similarities = []\n",
    "    for _, row in movieSet.iterrows():\n",
    "        if row['original_title'] != target_movie:\n",
    "            similarity = similarity_func(target_value, row[column])\n",
    "            similarities.append((row['original_title'], float(similarity)))  # Convert to normal float\n",
    "\n",
    "    # Proper sorting: Always prioritize smaller distances\n",
    "    sorted_results = sorted(similarities, key=lambda x: x[1], reverse=higher_is_better)\n",
    "\n",
    "    return sorted_results[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Star Wars: The Force Awakens', 223189436.0),\n",
       " ('The Avengers', 325476278.0),\n",
       " ('Jurassic World', 331505378.0),\n",
       " ('Furious 7', 338784828.0),\n",
       " ('Avengers: Age of Ultron', 439630494.0),\n",
       " ('Harry Potter and the Deathly Hallows: Part 2', 503034188.0),\n",
       " ('Frozen', 570815179.0),\n",
       " ('Beauty and the Beast', 582147851.0),\n",
       " ('The Fate of the Furious', 606269423.0),\n",
       " ('Iron Man 3', 629594194.0)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_top_similar_movies(\"Titanic\", \"revenue\", euclidean_distance, higher_is_better=False)\n",
    "\n",
    "# This works for this, as we validated it! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The Tie That Binds', 1.0),\n",
       " ('Dream Man', 1.0),\n",
       " ('O Convento', 1.0),\n",
       " ('Baton Rouge', 1.0),\n",
       " ('The Innocent Sleep', 1.0),\n",
       " ('U Turn', 1.0),\n",
       " ('Stag', 1.0),\n",
       " ('Stranger in the House', 1.0),\n",
       " ('Hard Rain', 1.0),\n",
       " ('Wild Things', 1.0)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_top_similar_movies(\"The Avengers\", \"genres\", jaccard_similarity, higher_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Toy Story', 1.0),\n",
       " ('Jumanji', 1.0),\n",
       " ('Waiting to Exhale', 1.0),\n",
       " ('Heat', 1.0),\n",
       " ('Sabrina', 1.0),\n",
       " ('Sudden Death', 1.0),\n",
       " ('GoldenEye', 1.0),\n",
       " ('The American President', 1.0),\n",
       " ('Nixon', 1.0),\n",
       " ('Cutthroat Island', 1.0)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO LOOK AT THIS EVENTUALLY \n",
    "\n",
    "# Ensure 'budget' contains only numeric values and replace invalid entries\n",
    "movieSet['budget'] = pd.to_numeric(movieSet['budget'], errors='coerce')\n",
    "\n",
    "# Replace NaN values (from bad data) with 0 or median budget\n",
    "movieSet['budget'] = movieSet['budget'].fillna(movieSet['budget'].median())\n",
    "\n",
    "# Convert back to integer for consistency\n",
    "movieSet['budget'] = movieSet['budget'].astype(int)\n",
    "\n",
    "# Run similarity search\n",
    "find_top_similar_movies(\"Interstellar\", \"budget\", cosine_sim, higher_is_better=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The Black Knight', 3.0),\n",
       " ('One Dark Night', 3.0),\n",
       " ('The Dark Angel', 4.0),\n",
       " ('The Good Night', 5.0),\n",
       " ('The Long Night', 5.0),\n",
       " ('The Dark Wind', 5.0),\n",
       " ('Shark Night', 5.0),\n",
       " ('The Big Night', 5.0),\n",
       " ('The Dark Past', 5.0),\n",
       " ('The Last Flight', 5.0)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_top_similar_movies(\"The Dark Knight\", \"original_title\", edit_distance, higher_is_better=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Star Wars: The Force Awakens', 719741463.0),\n",
       " ('Titanic', 942930899.0),\n",
       " ('The Avengers', 1268407177.0),\n",
       " ('Jurassic World', 1274436277.0),\n",
       " ('Furious 7', 1281715727.0),\n",
       " ('Avengers: Age of Ultron', 1382561393.0),\n",
       " ('Harry Potter and the Deathly Hallows: Part 2', 1445965087.0),\n",
       " ('Frozen', 1513746078.0),\n",
       " ('Beauty and the Beast', 1525078750.0),\n",
       " ('The Fate of the Furious', 1549200322.0)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_top_similar_movies(\"Avatar\", \"revenue\", euclidean_distance, higher_is_better=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sense and Sensibility', 0.0),\n",
       " ('The Rock', 0.0),\n",
       " ('North by Northwest', 0.0),\n",
       " ('A Clockwork Orange', 0.0),\n",
       " ('Shall we ダンス?', 0.0),\n",
       " ('Seven Years in Tibet', 0.0),\n",
       " ('He Got Game', 0.0),\n",
       " ('The Mask of Zorro', 0.0),\n",
       " (\"Rosemary's Baby\", 0.0),\n",
       " ('Star Wars: Episode I - The Phantom Menace', 0.0)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_top_similar_movies(\"The Matrix\", \"runtime\", manhattan_distance, higher_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sense and Sensibility', 0.0),\n",
       " ('The Rock', 0.0),\n",
       " ('North by Northwest', 0.0),\n",
       " ('A Clockwork Orange', 0.0),\n",
       " ('Shall we ダンス?', 0.0),\n",
       " ('Seven Years in Tibet', 0.0),\n",
       " ('He Got Game', 0.0),\n",
       " ('The Mask of Zorro', 0.0),\n",
       " (\"Rosemary's Baby\", 0.0),\n",
       " ('Star Wars: Episode I - The Phantom Menace', 0.0)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_top_similar_movies(\"The Matrix\", \"runtime\", manhattan_distance, higher_is_better=False)\n",
    "\n",
    "\n",
    "# Super exact results, but its right "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
